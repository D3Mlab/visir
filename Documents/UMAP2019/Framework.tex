%In this section, we first define the problem we address and  then the mathematical notation we use.  

%In this section, we will define our addressing problem with the notation. Also, the background about this paper will be provided.


%\subsection{Background}

%Standard unsupervised algorithms like $k$-means~\cite{kmeans_original} (and variants) that are commonly used for search results clustering define clusters according to a prototype document centroid in a vector space model, where all search results would be assigned to their closest cluster centroid.  While this approach naturally provides for topical (content) coherence of search results within a cluster, it does not directly guarantee high relevance of clusters.  It also does not directly guarantee coherence of display attributes of clusters such as the spatial and temporal extent of the cluster (i.e., a cluster may have documents spanning a large spatial or temporal range), unless these attributes are incorporated into the distance metric for the vector space model and appropriately traded off with content distance. 

\subsection{Problem definition}

In this paper, we take a novel perspective on the definition of a cluster and the optimization process for extracting these clusters. To start, we assume the search results have the following three display attributes that can be used to define coherent clusters in terms of spatial, temporal, and topical (i.e., content) constraints:
%of an AUI to ease the task of monitoring alerts in large-scale displayed networks. The new interface is expected to filter irrelevant information to provide localized context for each event or alert (defined loosely as a relevant related content localized in time, space, and/or keyword usage). \textcolor{red}{Hence, we argue that the problem we are addressing in this paper is an optimization problem of filter selection.  Furthermore, we assume that selection of information elements to display in a visual interface is obtained via settings of three filters that jointly express a global filter. These three sub-filters are:}
%%
%The problem we address in this paper is the proper display of portion in the network for user's easy to investigate large-scale network elements. The new system is expected to filter information to provide localized and relevant element in the interface. This problem is able to be defined as a filter search/recommendation problem, We expect to employ standard IR theory to solve this problem based on our argument about the similarity of AUI and IR system. We assume that display of the elements in the network is obtained via three filters that can jointly express a global filter. These three sub-filters are:
\begin{itemize}[topsep=2pt,leftmargin=*]
\item {\bf Space:} limits cluster content to 2D spatially annotated content (e.g., latitude and longitude) according to four parameters for the upper left and lower right bounding box coordinates.  These cluster constraints define the bounding box that is visually displayed to the user, cf. Figure~\ref{Fig:BPS_FilteredDisplay}.
\item {\bf Time:} limits cluster content to time-stamped results according to two parameters for the lower and upper time bound.  Time can be displayed via cluster labels, and/or through settings of a time slider in the interface.
%expresses a bounding box of a retrieved set. The location can be expressed as longitude/latitude values, or pure coordinates obtained using a given display layout. 
\item {\bf Keyword (or Discrete Attribute):} limits cluster content according to included or excluded keywords (or general discrete attributes of an information element).
Explicit included and excluded keywords can be used to label the cluster. 
\end{itemize}
Given a query and a probabilistic measure of relevance for each search result w.r.t.\ this query (e.g., from a language model~\cite{Zhai2001}), %the problem we address in this paper is how to efficiently optimize content filtering in a visual information display (VID) for
the problem we study is how to efficiently extract high-relevance clusters defined according to the above constraints.

%In general, we remark that the choice of which clustering parameters to use is up to the interactive search interface designer according to the display and (meta-)data available.  
We note that this clustering work is not limited to these three display attributes -- any continuous or discrete cluster attributes that naturally constrain the search results can be accommodated by our framework.  Nonetheless, we believe time, space, and content constitute three of the most common information display attributes in practice and hence are the ones we focus on in this work.
%one or multiple filter selection settings to maximize retrieval of relevant content?  
%\textcolor{red}{Even though in practice, not all data have such information associated, we can imagine throw away the sub-filters associated with the missing information, e.g., location information which is certainly not available in all datasets.} 
%best set of elements that is assessed using one of the metrics described above, i.e., expected precision, expected recall, or expected F1-score

\subsection{Mathematical Notation}

With the cluster definitions above, we now define  formal mathematical notation used throughout the remainder of the paper:
%portion of our presentation using  
%Throughout this paper, we present all algorithms for Greedy and Optimal search using 
%the following mathematical notation:

\begin{itemize}[topsep=2pt,leftmargin=*]
\item An information element $j$ (i.e., a search result) may have three types of associated metadata: (i) position coordinates $(x_{j},y_{j})$, (ii) a timestamp $t_j$, which may represent the creation date of $j$, and (iii) textual content, which is composed of a set of unique terms $\{ t_1,\ldots,t_n \}$ of size $n$ (to reduce notational clutter, we assume the element $j$ containing these terms will be clear from context).

\item Three variables $I(j) \in \{0,1\}$, $B(j) \in \{0,1\}$ and $S(j) \in [0,1]$ are associated with each information element $j$: $I(j)$ is an indicator referring to whether an element $j$ is retrieved and displayed ($\textrm{true}\!=\!1$); $B(j)$ is a Boolean random variable indicating the (ground truth) relevance of an element $j$ ($\textrm{relevant}\!=\!1$); $S(j)$ is a relevance score indicating the \emph{probability} relevance of an element $j$. %Note that $I(j)$ is correlated with the UI system. $B(j)$ and $S(j)$ are independent of the system. 
%$\emph{I(j), B(j)} \in \{0, 1\}$, $\emph{S(j)} \in \left[0, 1\right]$. 
$B(j)$ follows a \emph{Bernoulli} distribution with parameter $S(j)$, and hence, the expectation of $B(j)$ \emph{is} $S(j)$, i.e., 
  $\mathbb{E}[B(j)] = S(j)$.
%which allows to derive the expectation of \emph{B(j)} as follows:
%\begin{equation}
 % \mathbb{E_S}[B(j)] = 0*(1 - S(i))+ 1*S(i) = S(i)
%\end{equation}
\item We label $GC$ as the global set of all information elements $j$ with total size $|GC|=m$. %Two subsets of $GC$ are particularly important in this research: retrieved set $E$ and relevant set $RS$.  
\item $E$ is the set of retrieved information elements that match a user query, where $E \subseteq  GC$.  We use $E^*$ to refer to further subsets of elements of clusters, i.e., $E^*\subseteq E$. 
%This variable depends on the UI filtering system. 
Note that $|E|$ is the count of retrieved $I(j)$ among the global collection $GC$. Therefore, we have $|E| = \sum_{j=1}^m I(j)$.
\item We label the set of ground truth relevant information elements as the relevant set $RS$ consisting of $|RS|$ elements. 
%This is independent of the UI-filter system. 
Note that $|RS|$ is the count of relevant $B(j)$ among the global collection $GC$. Therefore, we have $|RS| = \sum_{j=1}^m B(j)$. %However, $B(j)$ is not available for our estimation of $RS$ size in practice. We have to use expected $RS$ size $|RS|$, $\mathbb{E_S}|RS|$, to approximate $|RS|$.
%\begin{equation}
  %|RS| \approx \mathbb{E_S}|RS| = \sum_{j=1}^m \mathbb{E_S}[B(j)] = \sum_{j=1}^m S(j)
%\end{equation}

%\item Keyword parameters $Q_k=\{\neg t_{1}^{*},\dots \neg t_{k}^{*}\}$, are composed of a set of query terms excluded from the cluster, i.e., elements in the cluster cannot contain the terms $t_{1}^{*},\dots t_{k}^{*}$.
%\item Time parameters $Q_t=[t_{start},t_{end}]$ express the lower bound $t_{start}$ and upper bound $t_{end}$ time parameters of the cluster.
%\item Position parameters $Q_p=[(x_{min},y_{min}),(x_{max},y_{max})]$ express the upper left $(x_{min},y_{min})$ and lower right $(x_{max},y_{max})$ corners of the spatial parameters of a cluster.%, assuming $(0,0)$ is in the upper left corner of the display window.  
%search of elements falling in the bounding box represented by the  lower and upper bound coordinates -- respectively $(x_{min},y_{min})$ and $(x_{max},y_{max})$.
%\item A cluster $Q$ combines the three selection parameters $Q_k$, $Q_t$, and $Q_p$ in a conjoined set of parameters $Q=[Q_k, Q_t, Q_p]$. 
%$Q=[Q_k\wedge Q_t\wedge Q_p]$. 

\end{itemize}







%The goal is to explore an algorithm to obtain an optimal filter setting to retrieve a set of elements with maximum score of the specific metric.



%\subsection{Comparison to standard IR search}
%The comparison between information retrieval for web search and information retrieval for filtering in AUIs can be summarized in Table \ref{tbl:Comparaison2IR}. Obviously , there are important differences between web search and filtering for AUIs, especially in the indirect selection of results through filter settings. This unexplored field provides new possibilities and challenges of research in this novel information retrieval setting:
%\begin{itemize}
%\item Evaluation metrics and human factors: Are there new evaluation metrics specific to this AUI filtering setting? What evaluation metrics correlate with AUI user performance? 
%\item Optimization and algorithms: How do we optimally select filter settings to maximize evaluation metrics in expectation? How can we interpret simple heuristics like average and cumulative relevance? (Answer: expected precision.) How do MILPs, relaxed LP approximations with guarantees, or greedy approaches compare in terms of time and metric quality? Are there properties of different filters (1D for time, 2D for bounding box, or discrete choices for property selection) that lend themselves to specialized greedy approaches? 
%\item Robustness: As the signal-to-noise ratio varied in the quality of the relevance scoring, how do various algorithms perform? 
%\item Explanation: Can we provide explanations for filter settings to allow users to understand the reasons for the suggestions? 
%\item Personalization and learning: Can we learn from observations of manual adaption of the suggested filter settings to understand how to improve the third-party scoring systems? 
%\item Collaborative filtering: Can we generalize learning across multiple
%users in a collaborative filtering approach? 
%\item Learning from implicit feedback: How can we leverage implicit user
%feedback such as clicks and dwell time to indirectly measure the relevance
%of filtered content and improve system performance.
%\end{itemize}

%\subsection{Optimization technique definition}

%The \emph{greedy algorithm} is an algorithmic paradigm that aims to obtain a global optimum of a problem in terms of making the locally optimal decision at each step \cite{Black2005}. In a search problem, a greedy algorithm does not in general produce an optimal solution, but it still yields locally optimal solutions that approximate a global optimum in a reasonable time.

%The greedy algorithms described in this paper are coupled with a \emph{Top-down} search strategy, which basically begins with the whole search space, and then partition into several sub-spaces in a lower level for the local optimization search heuristic.

%An \emph{optimization-based} search is the problem of finding the best solution from all feasible solutions. Usually, the standard form of an optimization problem is defined as the minimization/maximization of a given objective function subject to a set of constraints. 

%The search problem will be transformed into Mixed integer linear programming (MILP), which involves problems in which only some of the variables, $x_{i}$, are constrained to be integers, while other variables are allowed to be non-integers.



%\subsection{Evaluation metrics}




