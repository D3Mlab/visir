{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import bisect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from scipy.stats import t, ttest_ind\n",
    "from collections import Counter, OrderedDict\n",
    "import warnings\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "warnings.simplefilter('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch(ts):\n",
    "    \"\"\"\n",
    "    convert the daytime into epochtime\n",
    "    \"\"\"\n",
    "    \n",
    "    pattern = '%d-%m-%Y'\n",
    "    epochtime = int(time.mktime(time.strptime(ts, pattern)))\n",
    "    \n",
    "    return epochtime\n",
    "\n",
    "#def time_log(line):\n",
    "#    start = line.rfind(\"(\")+1\n",
    "#    middle = line.rfind(\",\")\n",
    "#    end = line.rfind(\")\")\n",
    "#    t1 = epoch(line[start:middle])\n",
    "#    t2 = epoch(line[middle+1:end])\n",
    "#    tr = [t1,t2]\n",
    "    \n",
    "#    return tr\n",
    "\n",
    "def time_diff(ts, te):\n",
    "    \"\"\"\n",
    "    compute time difference between two time nodes\n",
    "    \n",
    "    input\n",
    "    -----------------\n",
    "    ts, te: string of day-time (dd-mm-yy')\n",
    "    \n",
    "    return\n",
    "    -----------------\n",
    "    time_diff: time difference\n",
    "    \"\"\"\n",
    "    \n",
    "    t1_y = int(ts.split(\"-\")[0])\n",
    "    t1_m = int(ts.split(\"-\")[1])\n",
    "    t1_d = int(ts.split(\"-\")[2])\n",
    "        \n",
    "    #yyyy-mm-dd\n",
    "    \n",
    "    t2_y = int(te.split(\"-\")[0])\n",
    "    t2_m = int(te.split(\"-\")[1])\n",
    "    t2_d = int(te.split(\"-\")[2])   \n",
    "    \n",
    "    d1 = date(t1_y, t1_m, t1_d)\n",
    "    d2 = date(t2_y, t2_m, t2_d)\n",
    "    delta = d1 - d2\n",
    "    time_diff = abs(delta.days)\n",
    "    \n",
    "    return time_diff\n",
    "\n",
    "def real_sol():\n",
    "    \"\"\"\n",
    "    correct solution for the tasks in this experiment\n",
    "    \"\"\"\n",
    "    \n",
    "    sol ={}\n",
    "    l1 = ['flood,Colorado,2013-09-09','blizzard,New York,2014-02-11','hurricane,North Carolina,2014-07-01']\n",
    "    l2 = ['tornado,Oklahoma,2013-05-20','blizzard,Massachusetts,2014-02-06','earthquake,California,2014-08-24']    \n",
    "    l3 = ['hurricane,Florida,2013-06-09','earthquake,California,2014-03-17','blizzard,New York,2014-11-13', \n",
    "          'flood,Florida,2013-06-09']\n",
    "    sol['pos1,pos7,pos6'] = l1\n",
    "    sol['pos4,pos9,pos5'] = l2\n",
    "    sol['pos2,pos3,pos8'] = l3\n",
    "    \n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def each_effort(log_dict, algo, data, xkey, time, nd_list, location_list, nd_time, sol):\n",
    "    \"\"\"\n",
    "    write each effort's result into log_dict\n",
    "    1st level of keys in log_dict: actions, time_elapsed, query and other actions\n",
    "    2nd level of keys in log_dict: 'x', nd_precision and other metric\n",
    "    The value of log_dict is a nested list for different users' result\n",
    "    \n",
    "    input\n",
    "    -----------------\n",
    "    log_dict: previous log_dict; algo: string of algorithm ('kmeans'); data: string of data ('pos1,pos7,pos6');\n",
    "    xkey: string of 1st level key in log_dict; time: behavior epoch time in log file \n",
    "    nd_list, location_list, nd_time: current user's answer(list); sol: correct solution\n",
    "    \n",
    "    output\n",
    "    -----------------\n",
    "    log_dict: new log_dict with current effort\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # log effort part: the list with 'x' is used for x-value in plots\n",
    "    if(len(log_dict['actions']['x'])== 0):\n",
    "        log_dict['actions']['x'].append(1)\n",
    "    else:\n",
    "        log_dict['actions']['x'].append(log_dict['actions']['x'][-1]+1)\n",
    "    \n",
    "    log_dict['time_elapsed']['x'].append(time)     \n",
    "    \n",
    "    if(len(log_dict[xkey]['x'])!=0):\n",
    "        log_dict[xkey]['x'].append(log_dict[xkey]['x'][-1]+1)\n",
    "    else:\n",
    "        log_dict[xkey]['x'].append(1)\n",
    "    \n",
    "    \n",
    "    # log results part\n",
    "    \n",
    "    ylist = ['nd_precision', 'location_precision', 'nd_recall', 'location_recall','nd_time_deviation']\n",
    "    \n",
    "    nd_sol = [x.split(',')[0] for x in sol]\n",
    "    location_sol = [x.split(',')[1] for x in sol]\n",
    "    ndtime_sol = [x.split(',')[2] for x in sol]\n",
    "    # log result part\n",
    "    \n",
    "    nd_p = 0.000\n",
    "    nd_r = 0.000\n",
    "    location_p = 0.000\n",
    "    location_r = 0.000\n",
    "    time_err = 2190.000\n",
    "    #time_err = 0.000\n",
    "    \n",
    "    if(len(nd_list)!=0):\n",
    "        nd_corr = 0\n",
    "        location_corr = 0\n",
    "        time_err_current = 0.000\n",
    "        for i in range(len(nd_list)):\n",
    "            if(nd_list[i] in nd_sol):\n",
    "                nd_corr += 1\n",
    "            if(location_list[i] in location_sol):\n",
    "                location_corr += 1\n",
    "            if((nd_list[i] in nd_sol) and (location_list[i] in location_sol)): \n",
    "                k = nd_sol.index(nd_list[i])\n",
    "                time_err_current += time_diff(nd_time[i], ndtime_sol[k]) - 730\n",
    "            #if((nd_list[i] in nd_sol) and (location_list[i] in location_sol)): \n",
    "            #    k = nd_sol.index(nd_list[i])\n",
    "            #    time_err_current += time_diff(nd_time[i], ndtime_sol[k])\n",
    "            #else:\n",
    "            #    time_err_current += 730\n",
    "        \n",
    "        nd_p = float(nd_corr)/len(nd_list)\n",
    "        nd_r = float(nd_corr)/3.0\n",
    "        \n",
    "        location_p = float(location_corr)/len(location_list)\n",
    "        location_r = float(location_corr)/3.0\n",
    "        \n",
    "        time_err += time_err_current\n",
    "    \n",
    "    log_dict[xkey]['nd_precision'].append(nd_p)\n",
    "    log_dict['actions']['nd_precision'].append(nd_p)\n",
    "    log_dict['time_elapsed']['nd_precision'].append(nd_p)\n",
    "    log_dict[xkey]['nd_recall'].append(nd_r)\n",
    "    log_dict['actions']['nd_recall'].append(nd_r)\n",
    "    log_dict['time_elapsed']['nd_recall'].append(nd_r)\n",
    "    \n",
    "    log_dict[xkey]['location_precision'].append(location_p)\n",
    "    log_dict['actions']['location_precision'].append(location_p)\n",
    "    log_dict['time_elapsed']['location_precision'].append(location_p)\n",
    "    log_dict[xkey]['location_recall'].append(location_r)\n",
    "    log_dict['actions']['location_recall'].append(location_r)\n",
    "    log_dict['time_elapsed']['location_recall'].append(location_r)   \n",
    "    \n",
    "    log_dict[xkey]['nd_time_deviation'].append(time_err)\n",
    "    log_dict['actions']['nd_time_deviation'].append(time_err)\n",
    "    log_dict['time_elapsed']['nd_time_deviation'].append(time_err)\n",
    "    \n",
    "    \n",
    "    return log_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def each_log(logDir, logFile, real_sol, action):\n",
    "    \"\"\"\n",
    "    log file parsing \n",
    "    \n",
    "    input\n",
    "    -----------------\n",
    "    logDir: log directory; logFile: name of logfile; real_sol: correct solution\n",
    "    action: True for invidual action (This will add ending value of metric in each invidual action)\n",
    "            False for global field-time_elapsed and actions\n",
    "    output\n",
    "    -----------------\n",
    "    log_dict: new log_dict with current effort\n",
    "    \n",
    "    \"\"\"    \n",
    "    \n",
    "    fieldlist = ['query', 'slider', 'ZoomLevel', 'MouseDrag', 'checking_tweet',\n",
    "                 'checking_filter', 'time_elapsed', 'actions']    \n",
    "    ylist = ['nd_precision', 'nd_recall', 'location_precision', 'location_recall','nd_time_deviation'] \n",
    "    \n",
    "    log_dict = {} # save log infor\n",
    "    nds = []\n",
    "    locations = [] \n",
    "    ndtimes = []    \n",
    "    \n",
    "    for field in fieldlist:\n",
    "        log_dict[field] = {}\n",
    "        log_dict[field]['x'] = []\n",
    "        for y in ylist:\n",
    "            log_dict[field][y] = []\n",
    "            \n",
    "    log = logDir + logFile\n",
    "\n",
    "    with open(log, \"r\") as f:\n",
    "        i = 0\n",
    "        ts = 0\n",
    "        tsq = 0\n",
    "        tq = 0\n",
    "        algo = 'good'\n",
    "        data = 'good'\n",
    "        \n",
    "        ss = 0\n",
    "        \n",
    "        for line in f:\n",
    "            i += 1\n",
    "            line_split = line.split('\\t')\n",
    "            \n",
    "            if('START' in line_split[1]):               \n",
    "                algo = line_split[2]\n",
    "                data = line_split[-1][:-1]\n",
    "                log_dict['algo']= algo\n",
    "                log_dict['data']= data\n",
    "                sol = real_sol[data]\n",
    "                ts = float(line_split[0])/1000\n",
    "                \n",
    "            elif('Query_Execution' in line_split[1]):\n",
    "                teq = float(line_split[0])/1000\n",
    "                tq += (teq - tsq)\n",
    "            \n",
    "            elif('query' in line_split[1]):\n",
    "                xkey = 'query'\n",
    "                tsq = float(line_split[0])/1000\n",
    "                time_com = tsq - ts - tq\n",
    "                log_dict = each_effort(log_dict, algo, data, xkey, time_com, nds, locations, ndtimes, sol)\n",
    "                    \n",
    "            elif('slider' in line_split[1]):\n",
    "                xkey = 'slider'\n",
    "                time_com = float(line_split[0])/1000 - ts - tq\n",
    "                log_dict = each_effort(log_dict, algo, data, xkey, time_com, nds, locations, ndtimes, sol)\n",
    "                \n",
    "            elif('ZoomLevel' in line_split[1]):\n",
    "                xkey = 'ZoomLevel'\n",
    "                time_com = float(line_split[0])/1000 - ts - tq\n",
    "                log_dict = each_effort(log_dict, algo, data, xkey, time_com, nds, locations, ndtimes, sol)                \n",
    "            \n",
    "            elif('MouseDrag' in line_split[1]):\n",
    "                xkey = 'MouseDrag'\n",
    "                time_com = float(line_split[0])/1000 - ts - tq\n",
    "                log_dict = each_effort(log_dict, algo, data, xkey, time_com, nds, locations, ndtimes, sol) \n",
    "            \n",
    "            elif('clicking_tweet' in line_split[1]):\n",
    "                xkey = 'checking_tweet'\n",
    "                time_com = float(line_split[0])/1000 - ts - tq\n",
    "                log_dict = each_effort(log_dict, algo, data, xkey, time_com, nds, locations, ndtimes, sol) \n",
    "                                    \n",
    "            elif(('clicking_bbox' in line_split[1]) or ('adding_filter' in line_split[1])\n",
    "                 or ('removing_filter' in line_split[1])):\n",
    "                xkey = 'checking_filter'\n",
    "                time_com = float(line_split[0])/1000 - ts - tq                \n",
    "                log_dict = each_effort(log_dict, algo, data, xkey, time_com, nds, locations, ndtimes, sol)   \n",
    "                \n",
    "            elif('final_answer' in line_split[1]):\n",
    "                nds.append(line_split[3])\n",
    "                ndtimes.append(line_split[5])\n",
    "                locations.append(line_split[7][:-1])\n",
    "                time_com = float(line_split[0])/1000 - ts - tq\n",
    "                \n",
    "                ss += 1\n",
    "                \n",
    "                #if ((time_com > 800) and (algo == \"filters\")):\n",
    "                #    print logFile\n",
    "                    \n",
    "                if(action):\n",
    "                    #adding end value of metric in each invidual action\n",
    "                    for xkey in fieldlist[:-2]:\n",
    "                        log_dict = each_effort(log_dict, algo, data, xkey, time_com, nds, locations, ndtimes, sol)\n",
    "                else:\n",
    "                    log_dict = each_effort(log_dict, algo, data, xkey, time_com, nds, locations, ndtimes, sol)\n",
    "        if (ss > 3):\n",
    "            print logFile\n",
    "                \n",
    "        f.close()\n",
    "    \n",
    "    return log_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_log_initial():\n",
    "    \"\"\"\n",
    "    initializing a dict to save all log results\n",
    "    \n",
    "    output\n",
    "    -----------------\n",
    "    total_dict: empty dict\n",
    "    \n",
    "    \"\"\"    \n",
    "    fieldlist = ['query', 'slider', 'ZoomLevel', 'MouseDrag','checking_tweet',\n",
    "                'checking_filter', 'time_elapsed', 'actions']\n",
    "    \n",
    "    ylist = ['nd_precision', 'nd_recall', 'location_precision', 'location_recall','nd_time_deviation']\n",
    "    \n",
    "    algolist = ['baseline','kmeans','filters']\n",
    "    datalist = ['pos1,pos7,pos6','pos4,pos9,pos5','pos2,pos3,pos8']\n",
    "    \n",
    "    keylist = []\n",
    "    for algo in algolist:\n",
    "        for data in datalist:\n",
    "            keylist.append((algo, data))\n",
    "    \n",
    "    total_dict = {}\n",
    "    \n",
    "    for field in fieldlist:\n",
    "        total_dict[field] = {} \n",
    "        total_dict[field]['x'] = {}\n",
    "        for algo in algolist:\n",
    "            for key in keylist:             \n",
    "                total_dict[field]['x'][key] = []\n",
    "        for y in ylist:\n",
    "            total_dict[field][y] = {}\n",
    "            for key in keylist:            \n",
    "                total_dict[field][y][key] = []\n",
    "\n",
    "    return total_dict\n",
    "\n",
    "def total_log_writing(total_dict, log_dict):\n",
    "    \"\"\"\n",
    "    writing each log's dict into total dict\n",
    "    \n",
    "    input\n",
    "    -----------------\n",
    "    total_dict: current total dictionary result\n",
    "    log_dict: current log dictionary result     \n",
    "    \n",
    "    output\n",
    "    -----------------\n",
    "    total_dict: new total dictionary result\n",
    "    \"\"\" \n",
    "    \n",
    "    fieldlist = ['query', 'slider', 'ZoomLevel', 'MouseDrag', 'checking_tweet',\n",
    "                'checking_filter','time_elapsed', 'actions']\n",
    "    \n",
    "    ylist = ['nd_precision', 'nd_recall', 'location_precision', 'location_recall','nd_time_deviation']\n",
    "    \n",
    "    algo = log_dict['algo']\n",
    "    data = log_dict['data']\n",
    "    key = (algo, data)\n",
    "    \n",
    "    for f in fieldlist:\n",
    "        unnorm_x = log_dict[f]['x']\n",
    "        if(len(unnorm_x)!=0):\n",
    "            total_dict[f]['x'][key].append(unnorm_x)\n",
    "        \n",
    "        for y in ylist:            \n",
    "            total_dict[f][y][key].append(log_dict[f][y])\n",
    "    \n",
    "    return total_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp(X, Y, long_X):\n",
    "    \"\"\"\n",
    "    interpolate or extrapolate for miss X in long_X\n",
    "    \n",
    "    output\n",
    "    -----------------\n",
    "    y_eval: list of Y with the same size of long_X\n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    xs = set(X)\n",
    "    xp = list(long_X - xs) #Note long_X is Set\n",
    "    y_eval = [float(0.000)]*len(Y)\n",
    "    if(len(Y)!= 0):\n",
    "        yp = np.interp(xp, X, Y)\n",
    "        y_eval = [yv for _,yv in sorted(zip(X,Y)+zip(xp, yp))]\n",
    "    \n",
    "    return y_eval\n",
    "\n",
    "def polation(total_dict):\n",
    "    \"\"\"\n",
    "    interpolate or extrapolate for total_dict\n",
    "    \n",
    "    output\n",
    "    -----------------\n",
    "    pol_dict: a brand_new dict with interpolation or extrapolation treatment\n",
    "    \n",
    "    \"\"\" \n",
    "    pol_dict = total_log_initial()\n",
    "    \n",
    "    fieldlist = ['time_elapsed', 'actions', 'query', 'slider', 'ZoomLevel', 'MouseDrag',\n",
    "                 'checking_tweet','checking_filter']  \n",
    "    ylist = ['nd_precision', 'nd_recall', 'location_precision', 'location_recall','nd_time_deviation']\n",
    "    algolist = ['baseline','kmeans','filters']\n",
    "    datalist = ['pos1,pos7,pos6','pos4,pos9,pos5','pos2,pos3,pos8']\n",
    "    \n",
    "    for y in ylist:     \n",
    "        for f in fieldlist:\n",
    "            for algo in algolist:\n",
    "                keylist = []                \n",
    "                for data in datalist:\n",
    "                    keylist.append((algo, data))              \n",
    "                unflatten_x = []\n",
    "                unflatten_y = []\n",
    "                for key in keylist:\n",
    "                    lx = total_dict[f]['x'][key]\n",
    "                    ly = total_dict[f][y][key]\n",
    "                    unflatten_x += lx\n",
    "                    unflatten_y += ly\n",
    "\n",
    "                unflatten_x = filter(None, unflatten_x)\n",
    "                unflatten_y = filter(None, unflatten_y)  #remove empty nested-list \n",
    "                \n",
    "                if (len(unflatten_x)!=0):\n",
    "                    x_plot_set = set(reduce(lambda x1,x2: x1+x2,unflatten_x))\n",
    "                    x_plot = list(x_plot_set)\n",
    "                    x_plot.sort()\n",
    "                    pol_dict[f]['x'][key] = x_plot\n",
    "\n",
    "                    y_total = []\n",
    "                    for j in range(len(unflatten_x)):\n",
    "                        y_total_current = interp(unflatten_x[j], unflatten_y[j], x_plot_set)\n",
    "                        y_total.append(y_total_current)\n",
    "                        \n",
    "                    #    if(len(y_total[0])!= len(y_total_current)):\n",
    "                    #        print len(y_total_current)\n",
    "                    pol_dict[f][y][key] = y_total\n",
    "                                      \n",
    "    \n",
    "    return pol_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_algo_y(total_dict, filename, field_plots, user):\n",
    "    \"\"\"\n",
    "    plotting value in total_dict into pdf file\n",
    "    \n",
    "    input\n",
    "    -----------------\n",
    "    filename: pdf file name; field_plots: \"global\" for time_elapsed and actions\n",
    "    user: True for individual user plotting\n",
    "    \"\"\"     \n",
    "    \n",
    "    if(field_plots== \"global\"):\n",
    "        fieldlist = ['time_elapsed', 'actions']\n",
    "    else:\n",
    "        fieldlist = ['query', 'slider', 'ZoomLevel', 'MouseDrag', 'checking_tweet','checking_filter']   \n",
    "    \n",
    "    #ylist = ['nd_precision', 'nd_recall', 'location_precision', 'location_recall','nd_time_deviation']\n",
    "    ylist = ['nd_recall','location_recall','nd_time_deviation']\n",
    "    \n",
    "    algolist = ['baseline','kmeans','filters']\n",
    "    datalist = ['pos1,pos7,pos6','pos4,pos9,pos5','pos2,pos3,pos8']\n",
    "    \n",
    "    color_algo = ['blue','green','red']\n",
    "    \n",
    "    k = 1\n",
    "    pp = PdfPages(filename)\n",
    "    for y in ylist:     \n",
    "        for f in fieldlist:\n",
    "            fig = plt.figure(k)\n",
    "            ax = plt.axes()\n",
    "            ax.grid(True)\n",
    "            ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "            \n",
    "            for i in range(len(algolist)):\n",
    "                algo = algolist[i]\n",
    "                if not ((algo=='baseline') and (f=='checking_filter')):\n",
    "                    keylist = []                \n",
    "                    for data in datalist:\n",
    "                        keylist.append((algo, data))\n",
    "                    for key in keylist:\n",
    "                        lx = total_dict[f]['x'][key]\n",
    "                        ly = total_dict[f][y][key]\n",
    "                        \n",
    "                        if(len(lx)!=0):\n",
    "                            ym = np.mean(ly, axis = 0, dtype = float)\n",
    "                            ym[0] = 0.00\n",
    "\n",
    "                            if (y == \"nd_time_deviation\"):\n",
    "                                ym[0] = 2190.00                       \n",
    "\n",
    "                            if(user):\n",
    "                                plt.plot(lx, ym, linestyle='-', color=color_algo[i])                             \n",
    "                                for kk in range(len(ly)):\n",
    "                                    plt.plot(lx, ly[kk], linestyle=':', color=color_algo[i]) \n",
    "\n",
    "                            else:\n",
    "                                plt.plot(lx, ym, linestyle='-', color=color_algo[i], label=algo)\n",
    "                                ys = np.std(ly, axis= 0, dtype=float)\n",
    "\n",
    "                                df = len(ly)-1\n",
    "                                confidence = 0.95\n",
    "                                ts = t.ppf(1-(1 - confidence)/2.0, df)\n",
    "                                yi = ts * ys/math.sqrt(df)\n",
    "\n",
    "                                yl = ym - yi\n",
    "                                yu = ym + yi\n",
    "                                plt.fill_between(lx, yl, yu, alpha=0.1, edgecolor='', \n",
    "                                                 facecolor=color_algo[i], linewidth=0.0)                            \n",
    "                            \n",
    "            plt.title(f + ' VS '+ y)\n",
    "            if (f == \"time_elapsed\"):\n",
    "                plt.xlabel(f + \" (Sec)\")\n",
    "            else:\n",
    "                plt.xlabel(f)\n",
    "            if (y == \"nd_time_deviation\"):\n",
    "                plt.ylabel(y + \" (Day)\")\n",
    "                ax.set_ylim([0, 2500])                 \n",
    "            else:\n",
    "                plt.ylabel(y)\n",
    "                ax.set_ylim([0.0,1.2])                \n",
    "            plt.legend(ncol = 3)\n",
    "            k+= 1\n",
    "            \n",
    "            plt.savefig(\"plots/\"+f+\"_\"+y+\".pdf\", format='pdf')\n",
    "            plt.savefig(pp, format='pdf')\n",
    "            #plt.show()\n",
    "    \n",
    "    plt.close(\"all\")\n",
    "    pp.close()\n",
    "    \n",
    "    print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_algo_y_stage(total_dict, filename):\n",
    "    \"\"\"\n",
    "    plotting proportion of user reach threshold of recall\n",
    "    \"\"\"     \n",
    "    \n",
    "    rl = [0.33, 0.66, 0.99] \n",
    "    fieldlist = ['time_elapsed', 'actions']\n",
    "    ylist = ['nd_recall','location_recall']\n",
    "    \n",
    "    algolist = ['baseline','kmeans','filters']\n",
    "    datalist = ['pos1,pos7,pos6','pos4,pos9,pos5','pos2,pos3,pos8']\n",
    "    \n",
    "    color_algo = ['blue','green','red']\n",
    "    \n",
    "    k = 1\n",
    "    pp = PdfPages(filename)\n",
    "    for y in ylist:     \n",
    "        for f in fieldlist:\n",
    "            for ri in range(3):\n",
    "                fig = plt.figure(k)\n",
    "                ax = plt.axes()\n",
    "                ax.grid(True)\n",
    "                ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "                for i in range(len(algolist)):\n",
    "                    algo = algolist[i]\n",
    "                    keylist = []\n",
    "                    for data in datalist:\n",
    "                        keylist.append((algo, data))\n",
    "                    for key in keylist:\n",
    "                        lx = total_dict[f]['x'][key]\n",
    "                        ly = total_dict[f][y][key]\n",
    "                        if(len(lx)!=0):                       \n",
    "                            ly = np.array(ly)\n",
    "                            yp = []\n",
    "                            for ic in range(ly.shape[1]):\n",
    "                                su = sum(x > rl[ri] for x in ly[:, ic])\n",
    "                                yp.append(su/24.0)\n",
    "                            plt.plot(lx, yp, linestyle='-', color=color_algo[i], label = algolist[i])\n",
    "                \n",
    "                rt = 'good'\n",
    "                if(rl[ri]==0.33):\n",
    "                    rt = ' at level 1/3'\n",
    "                elif(rl[ri]==0.66):\n",
    "                    rt = ' at level 2/3'\n",
    "                elif(rl[ri]==0.99):\n",
    "                    rt = ' at level 3/3'\n",
    "                \n",
    "                plt.title(f + ' VS '+ y + rt)\n",
    "                if (f == \"time_elapsed\"):\n",
    "                    plt.xlabel(f + \" (Sec)\")\n",
    "                else:\n",
    "                    plt.xlabel(f)                \n",
    "                plt.ylabel(\"proportion of users\")\n",
    "                ax.set_ylim([0.0,1.2])                \n",
    "                plt.legend(ncol = 3)\n",
    "                k+= 1\n",
    "\n",
    "                plt.savefig(\"plots/\"+f+\"_\"+y+\"_\"+str(k)+\"_y_stage.pdf\", format='pdf')\n",
    "                plt.savefig(pp, format='pdf')\n",
    "                #plt.show()\n",
    "    \n",
    "    plt.close(\"all\")\n",
    "    pp.close()\n",
    "    \n",
    "    print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_level(r):\n",
    "    l = 0\n",
    "    if (r > 0.33) and (r < 0.66):\n",
    "        l = 1\n",
    "    elif (r > 0.66) and (r < 0.9):\n",
    "        l = 2\n",
    "    elif (r > 0.99):\n",
    "        l = 3\n",
    "\n",
    "    return l\n",
    "\n",
    "def plot_algo_stage(total_dict, filename, tk):\n",
    "    \"\"\"\n",
    "    plotting for performance distribution for different algorithms at different stage\n",
    "    \"\"\"\n",
    "    \n",
    "    xlist = ['time_elapsed', 'actions']\n",
    "    ylist = ['nd_recall', 'location_recall','nd_time_deviation']\n",
    "    #ylist = ['nd_recall', 'location_recall']\n",
    "    algolist = ['filters','kmeans','baseline']\n",
    "    datalist = ['pos1,pos7,pos6','pos4,pos9,pos5','pos2,pos3,pos8']\n",
    "    \n",
    "    highlight = [\"mean\",\"median\"]\n",
    "    \n",
    "    pp = PdfPages(filename)\n",
    "    \n",
    "    s = 1.0/tk\n",
    "    up_time = 1200\n",
    "    up_actions = 480\n",
    "    k = 1\n",
    "    t = 0\n",
    "    for x in xlist:\n",
    "        for y in ylist:\n",
    "            data_bar = OrderedDict()\n",
    "            vplot_data = OrderedDict()\n",
    "            for i in np.linspace(s, 1.0, tk):\n",
    "                if(x == 'time_elapsed'):\n",
    "                    t = i*up_time\n",
    "                else:\n",
    "                    t = i*up_actions                    \n",
    "                    \n",
    "                for algo in algolist:\n",
    "                    data_bar[algo] = [0, 0, 0, 0]\n",
    "                    vplot_data[algo] = []\n",
    "                    keylist = []                \n",
    "                    for data in datalist:\n",
    "                        keylist.append((algo, data))\n",
    "                    for key in keylist:\n",
    "                        lx = total_dict[x]['x'][key]                        \n",
    "                        ly = total_dict[x][y][key]\n",
    "                        \n",
    "                        if(len(lx)!=0):\n",
    "                            # directly get y value if target is in xlist                        \n",
    "                            if (t in lx):\n",
    "                                ind = lx.index(t)\n",
    "                                for l in ly:\n",
    "                                    yv = l[ind]\n",
    "                                    vplot_data[algo].append(yv)\n",
    "                                    data_bar[algo][answer_level(yv)] += 1\n",
    "\n",
    "                            # search two nearest elements for interpolation if target is not in xlist\n",
    "                            else:\n",
    "                                ub = bisect.bisect(lx, t)\n",
    "                                # ub == len(lx) if (t >= lx[-1])\n",
    "                                if(ub == len(lx)):\n",
    "                                    for l in ly:\n",
    "                                        yv = l[ub-1]                                        \n",
    "                                        vplot_data[algo].append(yv)\n",
    "                                        data_bar[algo][answer_level(yv)] += 1                                    \n",
    "                                        \n",
    "                                else:\n",
    "                                    xmax = lx[ub]\n",
    "                                    xmin = lx[ub-1]\n",
    "                                    for l in ly:\n",
    "                                        ymax = l[ub]\n",
    "                                        ymin = l[ub-1]\n",
    "                                        yv = np.interp(t, [xmin, xmax], [ymin, ymax])\n",
    "                                        vplot_data[algo].append(yv)\n",
    "                                        data_bar[algo][answer_level(yv)] += 1                                       \n",
    "                        \n",
    "                        #if(len(lx)!=0):\n",
    "                        #    xt = lx[int(i*len(lx))-1]\n",
    "                        #    for l in ly:\n",
    "                        #        vplot_data[algo].append(l[int(i*len(lx))-1])\n",
    "\n",
    "                fig = plt.figure(k)\n",
    "                k+= 1\n",
    "                ax = plt.axes()\n",
    "                #ax.grid(True)\n",
    "                ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "                \n",
    "                if (y=='nd_time_deviation'):\n",
    "                    labels, data = vplot_data.keys(), vplot_data.values()\n",
    "                    plt.boxplot(data, meanline=False)\n",
    "                    medians = np.percentile(data, 50, axis=1)\n",
    "                    means =  np.mean(data, dtype = float, axis=1)\n",
    "                    inds = np.arange(1, len(medians) + 1)\n",
    "                    ax.scatter(inds, medians, marker='o', color='red', label = \"median\")\n",
    "                    ax.scatter(inds, means, marker='o', color='black', label = \"mean\")\n",
    "\n",
    "                    plt.legend(ncol=2)\n",
    "                    plt.xticks(range(1, len(labels) + 1), labels)\n",
    "                    plt.ylabel('time_deviation (Day)')\n",
    "                    plt.yticks(np.arange(0, 3000, 500))                \n",
    "                    if(x == 'time_elapsed'):                \n",
    "                        plt.title('time_deviation VS algorithms at '+str(int(t))+' seconds')\n",
    "                    else: \n",
    "                        plt.title('time_deviation VS algorithms at '+str(int(t))+' actions')              \n",
    "                    plt.savefig(\"plots/\"+\"time_deviation_\"+x+\"_\"+str(int(t))+\".pdf\", format='pdf')\n",
    "                    plt.savefig(pp, format='pdf')\n",
    "                    plt.clf() # clear plots\n",
    "                \n",
    "                else:\n",
    "                    ########\n",
    "                    ## box plot for recall\n",
    "                    ########\n",
    "                    \n",
    "                    labels, data = vplot_data.keys(), vplot_data.values()\n",
    "                    plt.boxplot(data, meanline=False)\n",
    "                    medians = np.percentile(data, 50, axis=1)\n",
    "                    means =  np.mean(data, dtype = float, axis=1)\n",
    "                    inds = np.arange(1, len(medians) + 1)\n",
    "                    ax.scatter(inds, medians, marker='o', color='red', label = \"median\")\n",
    "                    ax.scatter(inds, means, marker='o', color='black', label = \"mean\")\n",
    "\n",
    "                    plt.legend(ncol=2)\n",
    "                    plt.xticks(range(1, len(labels) + 1), labels)\n",
    "                    plt.yticks(np.arange(0, 1.3, 0.1))  \n",
    "                    \n",
    "                    yt = y.split(\"_\")[0]\n",
    "\n",
    "                    if(x == 'time_elapsed'):                \n",
    "                        plt.title(yt+' recall VS algorithms at '+str(int(t))+' seconds')\n",
    "                    else: \n",
    "                        plt.title(yt+' recall VS algorithms at '+str(int(t))+' actions')  \n",
    "\n",
    "                    plt.savefig(\"plots/\"+y+\"_\"+x+\"_\"+str(int(t))+\".pdf\", format='pdf')\n",
    "                    plt.savefig(pp, format='pdf')                     \n",
    "                    \n",
    "                    \n",
    "        \n",
    "    plt.close(\"all\")\n",
    "    pp.close()\n",
    "    \n",
    "    print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_algo_final(total_dict, filename):\n",
    "    \"\"\"\n",
    "    violinplot plotting for distribution about number of actions and time_elased for different algorithms\n",
    "    \"\"\"     \n",
    "    \n",
    "    fieldlist = ['time_elapsed', 'actions', 'nd_recall', 'location_recall','nd_time_deviation']\n",
    "    algolist = ['filters','kmeans','baseline']\n",
    "    datalist = ['pos1,pos7,pos6','pos4,pos9,pos5','pos2,pos3,pos8']\n",
    "    highlight = [\"mean\",\"median\"]\n",
    "    \n",
    "    pp = PdfPages(filename)\n",
    "    \n",
    "    k = 1\n",
    "    for f in fieldlist:\n",
    "        plot_data = OrderedDict()\n",
    "        for algo in algolist:\n",
    "            plot_data[algo] = []\n",
    "            for data in datalist:\n",
    "                key = (algo, data)\n",
    "                if ((f == \"time_elapsed\") or (f == \"actions\")):\n",
    "                    lx = total_dict[f]['x'][key]\n",
    "                else:\n",
    "                    lx = total_dict[\"actions\"][f][key]\n",
    "                for l in lx:\n",
    "                    plot_data[algo].append(l[-1])\n",
    "\n",
    "        fig = plt.figure(k)\n",
    "        k+= 1\n",
    "        ax = plt.axes()\n",
    "        #ax.grid(True)\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.title(f + ' VS algorithms')\n",
    "        if (f == \"time_elapsed\"):\n",
    "            plt.ylabel(f + \" (Sec)\")\n",
    "        elif (f == \"nd_time_deviation\"):\n",
    "            plt.ylabel(f +\" (Day)\")            \n",
    "        else:\n",
    "            plt.ylabel(f)\n",
    "        \n",
    "        labels, data = plot_data.keys(), plot_data.values()\n",
    "        #plt.violinplot(data, showmeans=False, showextrema=False, showmedians=False)\n",
    "        \n",
    "        plt.boxplot(data, showmeans=False)\n",
    "        medians = np.percentile(data, 50, axis=1)\n",
    "        means =  np.mean(data, dtype = float, axis=1)\n",
    "        \n",
    "        inds = np.arange(1, len(medians) + 1)\n",
    "        ax.scatter(inds, medians, marker='o', color='red', label = \"median\")\n",
    "        ax.scatter(inds, means, marker='o', color='black', label = \"mean\")\n",
    "        \n",
    "        plt.xticks(range(1, len(labels) + 1), labels)\n",
    "        if ((f== 'nd_recall') or (f== 'location_recall')):\n",
    "            axes = plt.gca()\n",
    "            axes.set_ylim([None,1.1]) \n",
    "            \n",
    "        plt.legend(ncol = 2)\n",
    "        plt.savefig(\"plots/\"+ f + '_algorithms_final.pdf', format='pdf')        \n",
    "        plt.savefig(pp, format='pdf')       \n",
    "        #plt.show()\n",
    "        \n",
    "        #for algo in algolist:\n",
    "        #    print len(boxplot_data[algo])\n",
    "        \n",
    "    plt.close(\"all\")\n",
    "    pp.close()\n",
    "    \n",
    "    print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "log_dir = \"experiment_logs/\"\n",
    "#log_dir = \"one_log/\"\n",
    "rs = real_sol()\n",
    "\n",
    "#pdfname = \"plots_actions.pdf\"\n",
    "#total_dict = total_log_initial()\n",
    "#for filename in os.listdir(log_dir):\n",
    "#    one_dict = each_log(log_dir, filename, rs, True)\n",
    "#    total_dict = total_log_writing(total_dict, one_dict)\n",
    "#plot_algo(total_dict, pdfname, \"actions\", False)\n",
    "\n",
    "total_dict = total_log_initial()\n",
    "for filename in os.listdir(log_dir):\n",
    "    #print filename\n",
    "    one_dict = each_log(log_dir, filename, rs, False)\n",
    "    total_dict = total_log_writing(total_dict, one_dict)\n",
    "pol_dict = polation(total_dict)\n",
    "\n",
    "#pdfname = \"plots_global_each_user.pdf\"\n",
    "#plot_algo_y(pol_dict, pdfname, \"global\", True)    \n",
    "\n",
    "#pdfname = \"plots_global.pdf\"\n",
    "#plot_algo_y(pol_dict, pdfname, \"global\", False)\n",
    "\n",
    "pdfname = \"plots_final.pdf\"\n",
    "plot_algo_final(total_dict, pdfname)\n",
    "\n",
    "pdfname = \"plots_stage_bar.pdf\"\n",
    "tk = 4\n",
    "plot_algo_stage(pol_dict, pdfname, tk)\n",
    "\n",
    "#pdfname = \"plots_stage_line.pdf\"\n",
    "#plot_algo_y_stage(pol_dict, pdfname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following script is used to plot users' ranking responce in survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting users' ranking in survey\n",
    "\n",
    "rank = ['FKB','FKB','FKB','FKB','FKB','KBF','FKB','FKB','FKB','FKB','FKB','BFK','BFK','FBK','FKB', \n",
    "        'KBF','FKB','FBK','FKB','FKB','BFK','FKB','KFB','FKB']\n",
    "rr = OrderedDict()\n",
    "algolist = ['filters','kmeans','baseline']\n",
    "for algo in algolist:\n",
    "    rr[algo] = [0,0,0]\n",
    "    \n",
    "for r in rank:\n",
    "    for i in range(3):\n",
    "        algo = \"good\"\n",
    "        if(r[i]=='F'):\n",
    "            algo = \"filters\"\n",
    "        elif(r[i]=='K'):\n",
    "            algo = \"kmeans\"\n",
    "        elif(r[i]=='B'):\n",
    "            algo = 'baseline'\n",
    "        rr[algo][i] += 1       \n",
    "        \n",
    "labels, data = rr.keys(), rr.values()\n",
    "\n",
    "ind = np.arange(len(labels))    # the x locations for the groups\n",
    "width = 0.3       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "data_plot = [list(i) for i in zip(*data)]\n",
    "\n",
    "pp = PdfPages(\"survey.pdf\")\n",
    "\n",
    "p1 = plt.bar(ind, data_plot[2], width)\n",
    "p2 = plt.bar(ind, data_plot[1], width, bottom=np.array(data_plot[2]))\n",
    "p3 = plt.bar(ind, data_plot[0], width, bottom=np.array(data_plot[2])+np.array(data_plot[1]))\n",
    "\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(\"Users' Ranking of algorithms\")\n",
    "plt.xticks(ind, labels)\n",
    "plt.yticks(np.arange(0, 35, 5))\n",
    "plt.legend((p3[0], p2[0], p1[0]), ('1st','2nd','3rd'), ncol=3)\n",
    "\n",
    "plt.savefig('plots/survey.pdf', format='pdf')\n",
    "#plt.savefig(pp, format='pdf')   \n",
    "plt.show()\n",
    "\n",
    "pp.close()\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following script is used to plot users' responce of natural disaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'answers.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-84f89f60e8ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos1,pos7,pos6'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'answers.txt'"
     ]
    }
   ],
   "source": [
    "answer_file = \"answers.txt\"\n",
    "\n",
    "sol ={}\n",
    "answer_list = ['blizzard','drought','earthquake','flood','hurricane','tornado']\n",
    "#l1 = ['flood','blizzard','hurricane']\n",
    "#l2 = ['tornado','blizzard','earthquake']    \n",
    "#l3 = ['hurricane','earthquake,','blizzard']\n",
    "sol['pos1,pos7,pos6'] = [24,0,0,24,24,0]\n",
    "sol['pos4,pos9,pos5'] = [24,0,24,0,0,24]\n",
    "sol['pos2,pos3,pos8'] = [24,0,24,0,24,0]\n",
    "\n",
    "res = {}\n",
    "with open(answer_file, \"r\") as f:\n",
    "    i = 0\n",
    "    res['pos1,pos7,pos6'] = [0,0,0,0,0,0]\n",
    "    res['pos4,pos9,pos5'] = [0,0,0,0,0,0]\n",
    "    res['pos2,pos3,pos8'] = [0,0,0,0,0,0]\n",
    "    data = 'good'\n",
    "    for line in f:\n",
    "        i += 1\n",
    "        line_split = line.split('\\t')\n",
    "\n",
    "        if('START' in line_split[1]):\n",
    "            data = line_split[-1][:-1]\n",
    "        elif('answers'in line_split[1]):\n",
    "            a = line_split[3]\n",
    "            res[data][answer_list.index(a)] += 1\n",
    "            a = line_split[9]\n",
    "            res[data][answer_list.index(a)] += 1\n",
    "            a = line_split[15]\n",
    "            res[data][answer_list.index(a)] += 1\n",
    "        \n",
    "f.close()\n",
    "\n",
    "pp = PdfPages(\"response.pdf\")\n",
    "ind = np.arange(len(answer_list))\n",
    "width = 0.25\n",
    "k = 1\n",
    "for key in res.keys():\n",
    "    fig = plt.figure(k)\n",
    "    k+= 1\n",
    "    ax = plt.axes()\n",
    "    #ax.grid(True)\n",
    "    \n",
    "    p1 = plt.bar(ind, res[key], width)\n",
    "    p2 = plt.bar(ind+width, sol[key], width)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('User response VS solution (data '+str(k-1)+')')\n",
    "    plt.xticks(ind, answer_list) \n",
    "    plt.yticks(np.arange(0, 35, 5))\n",
    "    plt.legend((p1[0], p2[0]), ('response', 'solution'), ncol = 2)\n",
    "    plt.savefig(pp, format='pdf') \n",
    "    plt.savefig('plots/confusion_data_'+str(k-1)+'.pdf', format='pdf')\n",
    "    plt.show()\n",
    "\n",
    "plt.close(\"all\")\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
