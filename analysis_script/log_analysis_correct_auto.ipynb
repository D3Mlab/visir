{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from scipy.stats import t, ttest_ind\n",
    "import warnings\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "warnings.simplefilter('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def epoch(ts):\n",
    "    \"\"\"\n",
    "    convert the daytime into epochtime\n",
    "    \"\"\"\n",
    "    \n",
    "    pattern = '%d-%m-%Y'\n",
    "    epochtime = int(time.mktime(time.strptime(ts, pattern)))\n",
    "    \n",
    "    return epochtime\n",
    "\n",
    "#def time_log(line):\n",
    "#    start = line.rfind(\"(\")+1\n",
    "#    middle = line.rfind(\",\")\n",
    "#    end = line.rfind(\")\")\n",
    "#    t1 = epoch(line[start:middle])\n",
    "#    t2 = epoch(line[middle+1:end])\n",
    "#    tr = [t1,t2]\n",
    "    \n",
    "#    return tr\n",
    "\n",
    "def time_diff(ts, te):\n",
    "    \"\"\"\n",
    "    compute time difference between two time nodes\n",
    "    \n",
    "    input\n",
    "    -----------------\n",
    "    ts, te: string of day-time (dd-mm-yy')\n",
    "    \n",
    "    return\n",
    "    -----------------\n",
    "    time_diff: time difference\n",
    "    \"\"\"\n",
    "    \n",
    "    t1_y = int(ts.split(\"-\")[0])\n",
    "    t1_m = int(ts.split(\"-\")[1])\n",
    "    t1_d = int(ts.split(\"-\")[2])\n",
    "        \n",
    "    #yyyy-mm-dd\n",
    "    \n",
    "    t2_y = int(te.split(\"-\")[0])\n",
    "    t2_m = int(te.split(\"-\")[1])\n",
    "    t2_d = int(te.split(\"-\")[2])   \n",
    "    \n",
    "    d1 = date(t1_y, t1_m, t1_d)\n",
    "    d2 = date(t2_y, t2_m, t2_d)\n",
    "    delta = d1 - d2\n",
    "    time_diff = abs(delta.days)\n",
    "    \n",
    "    return time_diff\n",
    "\n",
    "def real_sol():\n",
    "    \"\"\"\n",
    "    correct solution for the tasks in this experiment\n",
    "    \"\"\"\n",
    "    \n",
    "    sol ={}\n",
    "    l1 = ['flood,Colorado,2013-09-09','blizzard,New York,2014-02-11','hurricane,North Carolina,2014-07-01']\n",
    "    l2 = ['tornado,Oklahoma,2013-05-20','blizzard,Massachusetts,2014-02-06','earthquake,California,2014-08-24']    \n",
    "    l3 = ['hurricane,Florida,2013-06-09','earthquake,California,2014-03-17','blizzard,New York,2014-11-13']\n",
    "    sol['pos1,pos7,pos6'] = l1\n",
    "    sol['pos4,pos9,pos5'] = l2\n",
    "    sol['pos2,pos3,pos8'] = l3\n",
    "    \n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def each_effort(log_dict, algo, data, xkey, time, nd_list, location_list, nd_time, sol):\n",
    "    \"\"\"\n",
    "    write each effort's result into log_dict\n",
    "    1st level of keys in log_dict: actions, time_elapsed, query and other actions\n",
    "    2nd level of keys in log_dict: 'x', nd_precision and other metric\n",
    "    The value of log_dict is a nested list for different users' result\n",
    "    \n",
    "    input\n",
    "    -----------------\n",
    "    log_dict: previous log_dict; algo: string of algorithm ('kmeans'); data: string of data ('pos1,pos7,pos6');\n",
    "    xkey: string of 1st level key in log_dict; time: behavior epoch time in log file \n",
    "    nd_list, location_list, nd_time: current user's answer(list); sol: correct solution\n",
    "    \n",
    "    output\n",
    "    -----------------\n",
    "    log_dict: new log_dict with current effort\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # log effort part: the list with 'x' is used for x-value in plots\n",
    "    if(len(log_dict['actions']['x'])== 0):\n",
    "        log_dict['actions']['x'].append(1)\n",
    "    else:\n",
    "        log_dict['actions']['x'].append(log_dict['actions']['x'][-1]+1)\n",
    "    \n",
    "    log_dict['time_elapsed']['x'].append(time)     \n",
    "    \n",
    "    if(len(log_dict[xkey]['x'])!=0):\n",
    "        log_dict[xkey]['x'].append(log_dict[xkey]['x'][-1]+1)\n",
    "    else:\n",
    "        log_dict[xkey]['x'].append(1)\n",
    "    \n",
    "    \n",
    "    # log results part\n",
    "    \n",
    "    ylist = ['nd_precision', 'location_precision', 'nd_recall', 'location_recall','nd_time_error']\n",
    "    \n",
    "    nd_sol = [x.split(',')[0] for x in sol]\n",
    "    location_sol = [x.split(',')[1] for x in sol]\n",
    "    ndtime_sol = [x.split(',')[2] for x in sol]\n",
    "    # log result part\n",
    "    \n",
    "    nd_p = 0.000\n",
    "    nd_r = 0.000\n",
    "    location_p = 0.000\n",
    "    location_r = 0.000\n",
    "    #time_err = 2190.000\n",
    "    time_err = 0.000\n",
    "    \n",
    "    if(len(nd_list)!=0):\n",
    "        nd_corr = 0\n",
    "        location_corr = 0\n",
    "        time_err_current = 0.000\n",
    "        for i in range(len(nd_list)):\n",
    "            if(nd_list[i] in nd_sol):\n",
    "                nd_corr += 1\n",
    "            if(location_list[i] in location_sol):\n",
    "                location_corr += 1\n",
    "            #if((nd_list[i] in nd_sol) and (location_list[i] in location_sol)): \n",
    "            #    k = nd_list.index(nd_list[i])\n",
    "            #    time_err_current += time_diff(nd_time[i], ndtime_sol[k]) - 730\n",
    "            if((nd_list[i] in nd_sol) and (location_list[i] in location_sol)): \n",
    "                k = nd_sol.index(nd_list[i])\n",
    "                time_err_current += time_diff(nd_time[i], ndtime_sol[k])\n",
    "            else:\n",
    "                time_err_current += 730\n",
    "        \n",
    "        nd_p = float(nd_corr)/len(nd_list)\n",
    "        nd_r = float(nd_corr)/3.0\n",
    "        \n",
    "        location_p = float(location_corr)/len(location_list)\n",
    "        location_r = float(location_corr)/3.0\n",
    "        \n",
    "        time_err += time_err_current\n",
    "    \n",
    "    log_dict[xkey]['nd_precision'].append(nd_p)\n",
    "    log_dict['actions']['nd_precision'].append(nd_p)\n",
    "    log_dict['time_elapsed']['nd_precision'].append(nd_p)\n",
    "    log_dict[xkey]['nd_recall'].append(nd_r)\n",
    "    log_dict['actions']['nd_recall'].append(nd_r)\n",
    "    log_dict['time_elapsed']['nd_recall'].append(nd_r)\n",
    "    \n",
    "    log_dict[xkey]['location_precision'].append(location_p)\n",
    "    log_dict['actions']['location_precision'].append(location_p)\n",
    "    log_dict['time_elapsed']['location_precision'].append(location_p)\n",
    "    log_dict[xkey]['location_recall'].append(location_r)\n",
    "    log_dict['actions']['location_recall'].append(location_r)\n",
    "    log_dict['time_elapsed']['location_recall'].append(location_r)   \n",
    "    \n",
    "    log_dict[xkey]['nd_time_error'].append(time_err)\n",
    "    log_dict['actions']['nd_time_error'].append(time_err)\n",
    "    log_dict['time_elapsed']['nd_time_error'].append(time_err)\n",
    "\n",
    "    return log_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def each_log(logDir, logFile, real_sol, action):\n",
    "    \"\"\"\n",
    "    log file parsing \n",
    "    \n",
    "    input\n",
    "    -----------------\n",
    "    logDir: log directory; logFile: name of logfile; real_sol: correct solution\n",
    "    action: True for invidual action (This will add ending value of metric in each invidual action)\n",
    "            False for global field-time_elapsed and actions\n",
    "    output\n",
    "    -----------------\n",
    "    log_dict: new log_dict with current effort\n",
    "    \n",
    "    \"\"\"    \n",
    "    \n",
    "    fieldlist = ['query', 'slider', 'ZoomLevel', 'MouseDrag', 'checking_tweet',\n",
    "                 'checking_filter', 'time_elapsed', 'actions']    \n",
    "    ylist = ['nd_precision', 'nd_recall', 'location_precision', 'location_recall','nd_time_error'] \n",
    "    \n",
    "    log_dict = {} # save log infor\n",
    "    nds = []\n",
    "    locations = [] \n",
    "    ndtimes = []    \n",
    "    \n",
    "    for field in fieldlist:\n",
    "        log_dict[field] = {}\n",
    "        log_dict[field]['x'] = []\n",
    "        for y in ylist:\n",
    "            log_dict[field][y] = []\n",
    "            \n",
    "    log = logDir + logFile\n",
    "    \n",
    "    lt = log_dict['time_elapsed']['location_recall']\n",
    "    \n",
    "    with open(log, \"r\") as f:\n",
    "        i = 0\n",
    "        ts = 0\n",
    "        tsq = 0\n",
    "        tq = 0\n",
    "        algo = 'good'\n",
    "        data = 'good'\n",
    "        xkey = 'query'\n",
    "        \n",
    "        for line in f:\n",
    "            i += 1\n",
    "            line_split = line.split('\\t')\n",
    "            \n",
    "            if('START' in line_split[1]):               \n",
    "                algo = line_split[2]\n",
    "                data = line_split[-1][:-1]\n",
    "                log_dict['algo']= algo\n",
    "                log_dict['data']= data\n",
    "                sol = real_sol[data]\n",
    "                ts = float(line_split[0])/1000\n",
    "                \n",
    "            elif('Query_Execution' in line_split[1]):\n",
    "                teq = float(line_split[0])/1000\n",
    "                tq += (teq - tsq)\n",
    "            \n",
    "            elif('query' in line_split[1]):\n",
    "                xkey = 'query'\n",
    "                tsq = float(line_split[0])/1000\n",
    "                time_com = tsq - ts - tq\n",
    "                log_dict = each_effort(log_dict, algo, data, xkey, time_com, nds, locations, ndtimes, sol)\n",
    "                    \n",
    "            elif('slider' in line_split[1]):\n",
    "                xkey = 'slider'\n",
    "                time_com = float(line_split[0])/1000 - ts - tq\n",
    "                log_dict = each_effort(log_dict, algo, data, xkey, time_com, nds, locations, ndtimes, sol)\n",
    "                \n",
    "            elif('ZoomLevel' in line_split[1]):\n",
    "                xkey = 'ZoomLevel'\n",
    "                time_com = float(line_split[0])/1000 - ts - tq\n",
    "                log_dict = each_effort(log_dict, algo, data, xkey, time_com, nds, locations, ndtimes, sol)                \n",
    "            \n",
    "            elif('MouseDrag' in line_split[1]):\n",
    "                xkey = 'MouseDrag'\n",
    "                time_com = float(line_split[0])/1000 - ts - tq\n",
    "                log_dict = each_effort(log_dict, algo, data, xkey, time_com, nds, locations, ndtimes, sol) \n",
    "            \n",
    "            elif('clicking_tweet' in line_split[1]):\n",
    "                xkey = 'checking_tweet'\n",
    "                time_com = float(line_split[0])/1000 - ts - tq\n",
    "                log_dict = each_effort(log_dict, algo, data, xkey, time_com, nds, locations, ndtimes, sol) \n",
    "                                    \n",
    "            elif(('clicking_bbox' in line_split[1]) or ('adding_filter' in line_split[1])\n",
    "                 or ('removing_filter' in line_split[1])):\n",
    "                xkey = 'checking_filter'\n",
    "                time_com = float(line_split[0])/1000 - ts - tq                \n",
    "                log_dict = each_effort(log_dict, algo, data, xkey, time_com, nds, locations, ndtimes, sol)   \n",
    "                \n",
    "            elif('final_answer' in line_split[1]):\n",
    "                nds.append(line_split[3])\n",
    "                ndtimes.append(line_split[5])\n",
    "                locations.append(line_split[7][:-1])\n",
    "                time_com = float(line_split[0])/1000 - ts - tq\n",
    "                if(action):\n",
    "                    #adding end value of metric in each invidual action\n",
    "                    for xkey in fieldlist[:-2]:\n",
    "                        log_dict = each_effort(log_dict, algo, data, xkey, time_com, nds, locations, ndtimes, sol)\n",
    "                else:\n",
    "                    log_dict = each_effort(log_dict, algo, data, xkey, time_com, nds, locations, ndtimes, sol)\n",
    "                \n",
    "        f.close()\n",
    "    \n",
    "    return log_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#log_dir = \"experiment_logs/\"\n",
    "#filename = 'logs_4_baseline.txt'\n",
    "#rs = real_sol()\n",
    "#one_dict = each_log(log_dir, filename, rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def total_log_initial():\n",
    "    \"\"\"\n",
    "    initializing a dict to save all log results\n",
    "    \n",
    "    output\n",
    "    -----------------\n",
    "    total_dict: empty dict\n",
    "    \n",
    "    \"\"\"    \n",
    "    fieldlist = ['query', 'slider', 'ZoomLevel', 'MouseDrag','checking_tweet',\n",
    "                'checking_filter', 'time_elapsed', 'actions']\n",
    "    \n",
    "    ylist = ['nd_precision', 'nd_recall', 'location_precision', 'location_recall','nd_time_error']\n",
    "    \n",
    "    algolist = ['baseline','kmeans','filters']\n",
    "    datalist = ['pos1,pos7,pos6','pos4,pos9,pos5','pos2,pos3,pos8']\n",
    "    \n",
    "    keylist = []\n",
    "    for algo in algolist:\n",
    "        for data in datalist:\n",
    "            keylist.append((algo, data))\n",
    "    \n",
    "    total_dict = {}\n",
    "    \n",
    "    for field in fieldlist:\n",
    "        total_dict[field] = {} \n",
    "        total_dict[field]['x'] = {}\n",
    "        for algo in algolist:\n",
    "            for key in keylist:             \n",
    "                total_dict[field]['x'][key] = []\n",
    "        for y in ylist:\n",
    "            total_dict[field][y] = {}\n",
    "            for key in keylist:            \n",
    "                total_dict[field][y][key] = []\n",
    "\n",
    "    return total_dict\n",
    "\n",
    "def total_log_writing(total_dict, log_dict):\n",
    "    \"\"\"\n",
    "    writing each log's dict into total dict\n",
    "    \n",
    "    input\n",
    "    -----------------\n",
    "    total_dict: current total dictionary result\n",
    "    log_dict: current log dictionary result     \n",
    "    \n",
    "    output\n",
    "    -----------------\n",
    "    total_dict: new total dictionary result\n",
    "    \"\"\" \n",
    "    \n",
    "    fieldlist = ['query', 'slider', 'ZoomLevel', 'MouseDrag', 'checking_tweet',\n",
    "                'checking_filter','time_elapsed', 'actions']\n",
    "    \n",
    "    ylist = ['nd_precision', 'nd_recall', 'location_precision', 'location_recall','nd_time_error']\n",
    "    \n",
    "    algo = log_dict['algo']\n",
    "    data = log_dict['data']\n",
    "    key = (algo, data)\n",
    "    \n",
    "    for f in fieldlist:\n",
    "        unnorm_x = log_dict[f]['x']\n",
    "        if(len(unnorm_x)!=0):\n",
    "            total_dict[f]['x'][key].append(unnorm_x)\n",
    "        \n",
    "        for y in ylist:            \n",
    "            total_dict[f][y][key].append(log_dict[f][y])\n",
    "    \n",
    "    return total_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def interp(X, Y, long_X):\n",
    "    \"\"\"\n",
    "    interpolate or extrapolate for miss X in long_X\n",
    "    \n",
    "    output\n",
    "    -----------------\n",
    "    y_eval: list of Y with the same size of long_X\n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    xs = set(X)\n",
    "    xp = list(long_X - xs) #Note long_X is Set\n",
    "    y_eval = [float(0.000)]*len(Y)\n",
    "    if(len(Y)!= 0):\n",
    "        yp = np.interp(xp, X, Y)\n",
    "        y_eval = [yv for _,yv in sorted(zip(X,Y)+zip(xp, yp))]\n",
    "    \n",
    "    return y_eval\n",
    "\n",
    "def plot_algo(total_dict, filename, field_plots, user):\n",
    "    \"\"\"\n",
    "    plotting value in total_dict into pdf file\n",
    "    \n",
    "    input\n",
    "    -----------------\n",
    "    filename: pdf file name; field_plots: \"global\" for time_elapsed and actions\n",
    "    user: True for individual user plotting\n",
    "    \"\"\"     \n",
    "    \n",
    "    if(field_plots== \"global\"):\n",
    "        fieldlist = ['time_elapsed', 'actions']\n",
    "    else:\n",
    "        fieldlist = ['query', 'slider', 'ZoomLevel', 'MouseDrag', 'checking_tweet','checking_filter']   \n",
    "    \n",
    "    #ylist = ['nd_precision', 'nd_recall', 'location_precision', 'location_recall','nd_time_error']\n",
    "    ylist = ['nd_recall','location_recall','nd_time_error']\n",
    "    \n",
    "    algolist = ['baseline','kmeans','filters']\n",
    "    datalist = ['pos1,pos7,pos6','pos4,pos9,pos5','pos2,pos3,pos8']\n",
    "    \n",
    "    color_algo = ['blue','green','red']\n",
    "    \n",
    "    k = 1\n",
    "    pp = PdfPages(filename)\n",
    "    for y in ylist:     \n",
    "        for f in fieldlist:\n",
    "            fig = plt.figure(k)\n",
    "            ax = plt.axes()\n",
    "            ax.grid(True)\n",
    "            ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "            for i in range(len(algolist)):\n",
    "                algo = algolist[i]\n",
    "                if not ((algo=='baseline') and (f=='checking_filter')):\n",
    "                    keylist = []                \n",
    "                    for data in datalist:\n",
    "                        keylist.append((algo, data))              \n",
    "                    unflatten_x = []\n",
    "                    unflatten_y = []\n",
    "                    lx = []\n",
    "                    ly = []\n",
    "                    for key in keylist:\n",
    "                        lx = total_dict[f]['x'][key]\n",
    "                        ly = total_dict[f][y][key]\n",
    "                        unflatten_x += lx\n",
    "                        unflatten_y += ly\n",
    "\n",
    "                    unflatten_x = filter(None, unflatten_x)\n",
    "                    unflatten_y = filter(None, unflatten_y)  #remove empty nested-list \n",
    "\n",
    "                    if (len(unflatten_x)!=0):\n",
    "                        x_plot_set = set(reduce(lambda x1,x2: x1+x2,unflatten_x))\n",
    "                        x_plot = list(x_plot_set)\n",
    "                        x_plot.sort()\n",
    "                        y_total = []\n",
    "\n",
    "                        for j in range(len(unflatten_x)):\n",
    "                            y_total_current = interp(unflatten_x[j], unflatten_y[j], x_plot_set)\n",
    "                            y_total.append(y_total_current)\n",
    "\n",
    "                        if(len(x_plot)!=0):\n",
    "                            ym = np.mean(y_total, axis = 0, dtype = float)\n",
    "\n",
    "                            if(user):\n",
    "                                plt.plot(x_plot, ym, linestyle='-', color=color_algo[i])                             \n",
    "                                for k in range(len(y_total)):\n",
    "                                    plt.plot(x_plot, y_total[k], linestyle=':', color=color_algo[i]) \n",
    "                                \n",
    "                            else:\n",
    "                                plt.plot(x_plot, ym, linestyle='-', color=color_algo[i], label=algo+'_mean')\n",
    "                                ys = np.std(y_total, axis= 0, dtype=float)\n",
    "                                \n",
    "                                df = len(y_total)-1\n",
    "                                confidence = 0.95\n",
    "                                ts = t.ppf(1-(1 - confidence)/2.0, df)\n",
    "                                yi = ts * ys/math.sqrt(df)\n",
    "                                \n",
    "                                yl = ym - yi\n",
    "                                yu = ym + yi\n",
    "                                plt.fill_between(x_plot, yl, yu, alpha=0.1, edgecolor='', \n",
    "                                                 facecolor=color_algo[i], linewidth=0.0)                            \n",
    "                            \n",
    "            plt.title(f + ' VS '+ y)\n",
    "            if (f == \"time_elapsed\"):\n",
    "                plt.xlabel(f + \" (Sec)\")\n",
    "            else:\n",
    "                plt.xlabel(f)\n",
    "            if (y == \"nd_time_error\"):\n",
    "                plt.ylabel(y + \" (Day)\")\n",
    "            else:\n",
    "                plt.ylabel(y)\n",
    "                ax.set_ylim([0.0,1.0])                \n",
    "            plt.legend()\n",
    "            k+= 1\n",
    "            \n",
    "            #plt.savefig(f+\"_\"+y, format='eps')\n",
    "            plt.savefig(pp, format='pdf')\n",
    "            #plt.show()\n",
    "    \n",
    "    plt.close(\"all\")\n",
    "    pp.close()\n",
    "    \n",
    "    print k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def boxplot_algo(total_dict, filename):\n",
    "    \"\"\"\n",
    "    box plotting for distribution about number of actions and time_elased for different algorithms\n",
    "    \"\"\"     \n",
    "    \n",
    "    fieldlist = ['time_elapsed', 'actions']\n",
    "    algolist = ['baseline','kmeans','filters']\n",
    "    datalist = ['pos1,pos7,pos6','pos4,pos9,pos5','pos2,pos3,pos8']\n",
    "    \n",
    "    pp = PdfPages(filename)\n",
    "    \n",
    "    k = 1\n",
    "    for f in fieldlist:\n",
    "        boxplot_data = {}\n",
    "        fig = plt.figure(k)\n",
    "        k+= 1\n",
    "        ax = plt.axes()\n",
    "        #ax.grid(True)\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        for algo in algolist:\n",
    "            boxplot_data[algo] = []\n",
    "            for data in datalist:\n",
    "                key = (algo, data)\n",
    "                lx = total_dict[f]['x'][key]\n",
    "                for l in lx:\n",
    "                    boxplot_data[algo].append(max(l))\n",
    "                \n",
    "        if (f == \"time_elapsed\"):\n",
    "            plt.ylabel(f + \" (Sec)\")\n",
    "        else:\n",
    "            plt.ylabel(f)\n",
    "        \n",
    "        labels, data = boxplot_data.keys(), boxplot_data.values()\n",
    "        plt.boxplot(data, showmeans=True)\n",
    "        plt.xticks(range(1, len(labels) + 1), labels)\n",
    "        plt.savefig(pp, format='pdf')\n",
    "        #plt.show()\n",
    "        \n",
    "        #for algo in algolist:\n",
    "        #    print len(boxplot_data[algo])\n",
    "        \n",
    "    plt.close(\"all\")\n",
    "    pp.close()\n",
    "    \n",
    "    print k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In each plot, solid line and dot line are used for mean and mean +/- standard deviation\n",
    "### Blue is for baseline algorithm,  green is for kmeans, and red is for filters.\n",
    "### Also, note that all completion time is squashed into (0.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "25\n",
      "7\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "log_dir = \"experiment_logs/\"\n",
    "#log_dir = \"one_log/\"\n",
    "rs = real_sol()\n",
    "\n",
    "pdfname = \"plots_actions.pdf\"\n",
    "total_dict = total_log_initial()\n",
    "for filename in os.listdir(log_dir):\n",
    "    one_dict = each_log(log_dir, filename, rs, True)\n",
    "    total_dict = total_log_writing(total_dict, one_dict)\n",
    "plot_algo(total_dict, pdfname, \"actions\", False)\n",
    "\n",
    "pdfname = \"plots_global_user.pdf\"\n",
    "total_dict = total_log_initial()\n",
    "for filename in os.listdir(log_dir):\n",
    "    #print filename\n",
    "    one_dict = each_log(log_dir, filename, rs, False)\n",
    "    total_dict = total_log_writing(total_dict, one_dict)\n",
    "plot_algo(total_dict, pdfname, \"global\", True)    \n",
    "\n",
    "pdfname = \"plots_global.pdf\"\n",
    "plot_algo(total_dict, pdfname, \"global\", False)\n",
    "\n",
    "pdfname = \"plots_global_boxplot.pdf\"\n",
    "boxplot_algo(total_dict, pdfname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
